{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38fc0149-455c-495d-8428-ec6e9ad64418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2023.7.22)\n",
      "Collecting scrapy\n",
      "  Using cached Scrapy-2.11.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting Twisted>=18.9.0 (from scrapy)\n",
      "  Using cached twisted-24.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.11/site-packages (from scrapy) (41.0.4)\n",
      "Collecting cssselect>=0.9.1 (from scrapy)\n",
      "  Using cached cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting itemloaders>=1.0.1 (from scrapy)\n",
      "  Using cached itemloaders-1.2.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting parsel>=1.5.0 (from scrapy)\n",
      "  Using cached parsel-1.9.1-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in /opt/conda/lib/python3.11/site-packages (from scrapy) (23.2.0)\n",
      "Collecting queuelib>=1.4.2 (from scrapy)\n",
      "  Using cached queuelib-1.7.0-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting service-identity>=18.1.0 (from scrapy)\n",
      "  Using cached service_identity-24.1.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\n",
      "  Using cached w3lib-2.1.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting zope.interface>=5.1.0 (from scrapy)\n",
      "  Using cached zope.interface-6.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (42 kB)\n",
      "Collecting protego>=0.1.15 (from scrapy)\n",
      "  Using cached Protego-0.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting itemadapter>=0.1.0 (from scrapy)\n",
      "  Using cached itemadapter-0.9.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from scrapy) (68.2.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from scrapy) (23.2)\n",
      "Collecting tldextract (from scrapy)\n",
      "  Using cached tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting lxml>=4.4.1 (from scrapy)\n",
      "  Downloading lxml-5.2.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
      "  Using cached PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=36.0.0->scrapy) (1.16.0)\n",
      "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.11/site-packages (from service-identity>=18.1.0->scrapy) (23.1.0)\n",
      "Collecting pyasn1 (from service-identity>=18.1.0->scrapy)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pyasn1-modules (from service-identity>=18.1.0->scrapy)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting automat>=0.8.0 (from Twisted>=18.9.0->scrapy)\n",
      "  Using cached Automat-22.10.0-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting constantly>=15.1 (from Twisted>=18.9.0->scrapy)\n",
      "  Using cached constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting hyperlink>=17.1.1 (from Twisted>=18.9.0->scrapy)\n",
      "  Using cached hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting incremental>=22.10.0 (from Twisted>=18.9.0->scrapy)\n",
      "  Using cached incremental-22.10.0-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from Twisted>=18.9.0->scrapy) (4.8.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from tldextract->scrapy) (3.4)\n",
      "Requirement already satisfied: requests>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
      "  Using cached requests_file-2.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting filelock>=3.0.8 (from tldextract->scrapy)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from automat>=0.8.0->Twisted>=18.9.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (2023.7.22)\n",
      "Using cached Scrapy-2.11.1-py2.py3-none-any.whl (287 kB)\n",
      "Using cached cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached itemadapter-0.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached itemloaders-1.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading lxml-5.2.2-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached parsel-1.9.1-py2.py3-none-any.whl (17 kB)\n",
      "Using cached Protego-0.3.1-py2.py3-none-any.whl (8.5 kB)\n",
      "Using cached PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Using cached queuelib-1.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Using cached service_identity-24.1.0-py3-none-any.whl (12 kB)\n",
      "Using cached twisted-24.3.0-py3-none-any.whl (3.2 MB)\n",
      "Using cached w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Using cached zope.interface-6.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n",
      "Using cached tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
      "Using cached Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Using cached constantly-23.10.4-py3-none-any.whl (13 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Using cached incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Installing collected packages: PyDispatcher, incremental, zope.interface, w3lib, queuelib, pyasn1, protego, lxml, jmespath, itemadapter, hyperlink, filelock, cssselect, constantly, automat, Twisted, requests-file, pyasn1-modules, parsel, tldextract, service-identity, itemloaders, scrapy\n",
      "Successfully installed PyDispatcher-2.0.7 Twisted-24.3.0 automat-22.10.0 constantly-23.10.4 cssselect-1.2.0 filelock-3.14.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.9.0 itemloaders-1.2.0 jmespath-1.0.1 lxml-5.2.2 parsel-1.9.1 protego-0.3.1 pyasn1-0.6.0 pyasn1-modules-0.4.0 queuelib-1.7.0 requests-file-2.0.0 scrapy-2.11.1 service-identity-24.1.0 tldextract-5.1.2 w3lib-2.1.2 zope.interface-6.3\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement re (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for re\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install scrapy\n",
    "!pip install re\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32de5841-845b-4d99-8a16-3ef05ec44869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from scrapy import Selector\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3918f385-f0e8-4f95-a9d4-f2973b0b9b71",
   "metadata": {},
   "source": [
    "ABS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01290737-c90e-400d-b549-be5dfaabe9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_smoking_rates_abs():\n",
    "    # URL of the page you want to scrape\n",
    "    url = \"https://www.abs.gov.au/statistics/health/health-conditions-and-risks/smoking/latest-release\"\n",
    "\n",
    "    # Send HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Use Scrapy's Selector to parse HTML content\n",
    "        selector = Selector(text=response.text)\n",
    "\n",
    "        # Extract data from the specified table with the aria-label attribute or caption\n",
    "        rows = selector.xpath('//table[caption[contains(text(), \"Proportion of people 15 years and over who were current daily smokers by age and sex, 2022\")]]/tbody/tr')\n",
    "        return_dict = {}\n",
    "        for row in rows:\n",
    "            # Extract data from each row, handling possible missing data gracefully\n",
    "            age_group = row.xpath('.//th/text()').get(default=\"N/A\").strip()\n",
    "            males_percentage = row.xpath('.//td[1]/text()').get(default=\"N/A\").strip()\n",
    "            males_low_ci = row.xpath('.//td[2]/text()').get(default=\"N/A\").strip()\n",
    "            males_high_ci = row.xpath('.//td[3]/text()').get(default=\"N/A\").strip()\n",
    "            females_percentage = row.xpath('.//td[4]/text()').get(default=\"N/A\").strip()\n",
    "            females_low_ci = row.xpath('.//td[5]/text()').get(default=\"N/A\").strip()\n",
    "            females_high_ci = row.xpath('.//td[6]/text()').get(default=\"N/A\").strip()\n",
    "            \n",
    "            print(f\"{age_group}: Males {males_percentage}% (CI {males_low_ci}-{males_high_ci}), Females {females_percentage}% (CI {females_low_ci}-{females_high_ci})\")\n",
    "            return_dict[age_group] = {\"Males\": float(males_percentage)/100, 'Females': float(females_percentage)/100}\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(return_dict)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to retrieve data. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b2bf80-1463-4d20-836c-3431946ed993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15–17(a): Males 1.2% (CI N/A-N/A), Females 1.8% (CI N/A-N/A)\n",
      "18–24: Males 9.3% (CI 6.4-12.2), Females 5.9% (CI 2.4-9.4)\n",
      "25–34: Males 13.4% (CI 10.2-16.6), Females 8.8% (CI 6.5-11.1)\n",
      "35–44: Males 13.5% (CI 10.5-16.5), Females 8.5% (CI 6.5-10.5)\n",
      "45–54: Males 15.3% (CI 12.3-18.3), Females 11.6% (CI 8.5-14.7)\n",
      "55–64: Males 17.4% (CI 13.8-21.0), Females 12.0% (CI 10.3-13.7)\n",
      "65–74: Males 9.9% (CI 7.4-12.4), Females 7.9% (CI 5.8-10.0)\n",
      "75 years and over: Males 3.8% (CI 1.1-6.5), Females 1.9% (CI 0.7-3.1)\n",
      "\n",
      "\n",
      "{'15–17(a)': {'Males': 0.012, 'Females': 0.018000000000000002}, '18–24': {'Males': 0.09300000000000001, 'Females': 0.059000000000000004}, '25–34': {'Males': 0.134, 'Females': 0.08800000000000001}, '35–44': {'Males': 0.135, 'Females': 0.085}, '45–54': {'Males': 0.153, 'Females': 0.11599999999999999}, '55–64': {'Males': 0.174, 'Females': 0.12}, '65–74': {'Males': 0.099, 'Females': 0.079}, '75 years and over': {'Males': 0.038, 'Females': 0.019}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fetch_smoking_rates_abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8015b2-2cc1-4854-b834-3f36b609254d",
   "metadata": {},
   "source": [
    "CDC DATA NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6141ad92-bc3d-488a-918d-390e76454c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_smoking_rates_cdc():\n",
    "    url = \"https://www.cdc.gov/tobacco/data_statistics/fact_sheets/adult_data/cig_smoking/index.htm\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        selector = Selector(text=response.text)\n",
    "\n",
    "        # Extract smoking rates by sex\n",
    "        male_rate_text = selector.xpath(\"//li[contains(text(), 'adult men')]/text()\").get()\n",
    "        female_rate_text = selector.xpath(\"//li[contains(text(), 'adult women')]/text()\").get()\n",
    "\n",
    "        male_rate = float(re.search(r\"(\\d+\\.\\d+)\", male_rate_text).group(1))\n",
    "        female_rate = float(re.search(r\"(\\d+\\.\\d+)\", female_rate_text).group(1))\n",
    "\n",
    "        print(f\"male rate: {male_rate}\")\n",
    "        print(f\"female rate: {female_rate}\")\n",
    "\n",
    "        # Calculate the correction factor for men's smoking rates\n",
    "        if female_rate != 0:\n",
    "            correction_factor = male_rate / female_rate\n",
    "        else:\n",
    "            correction_factor = 1\n",
    "\n",
    "        # Extract smoking rates by age group\n",
    "        age_groups = selector.xpath(\"//div[h4[contains(text(), 'By Age')]]/following-sibling::div//ul/li\")\n",
    "        age_smoking_rates = {}\n",
    "        for group in age_groups:\n",
    "            details = group.xpath(\".//text()\").get()\n",
    "            age_range_match = re.search(r\"(\\d+[\\–\\-]\\d+ years|\\d+ years and older)\", details)\n",
    "            if age_range_match:\n",
    "                age_range = age_range_match.group(1)\n",
    "                age_range_rate = float(re.search(r\"(\\d+\\.\\d+)\", details).group(1))\n",
    "                print(f\"age group-{age_range}: rate-{age_range_rate}\")\n",
    "                adjusted_rate = age_range_rate * correction_factor\n",
    "\n",
    "                # Store rates for both men and women\n",
    "                age_smoking_rates[age_range] = {\n",
    "                    'female_rate': age_range_rate,\n",
    "                    'male_rate': adjusted_rate\n",
    "                }\n",
    "\n",
    "        return age_smoking_rates\n",
    "    else:\n",
    "        print(\"Failed to retrieve data. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed2e701c-c0ee-4856-8e68-6eb5605b8350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male rate: 13.1\n",
      "female rate: 10.1\n",
      "age group-18–24 years: rate-5.3\n",
      "age group-25–44 years: rate-12.6\n",
      "age group-45–64 years: rate-14.9\n",
      "age group-65 years and older: rate-8.3\n",
      "\n",
      "\n",
      "{'18–24 years': {'female_rate': 5.3, 'male_rate': 6.874257425742575}, '25–44 years': {'female_rate': 12.6, 'male_rate': 16.342574257425742}, '45–64 years': {'female_rate': 14.9, 'male_rate': 19.325742574257426}, '65 years and older': {'female_rate': 8.3, 'male_rate': 10.765346534653467}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smoking_rates = fetch_smoking_rates_cdc()\n",
    "if smoking_rates:\n",
    "    print(\"\\n\")\n",
    "    print(smoking_rates)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd79967-ad99-4641-ac81-f9ffd4b83a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
